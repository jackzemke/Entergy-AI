{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "import csv\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 315 meeting links to puct_meeting_links.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "BASE_URL = \"https://www.adminmonitor.com/tx/puct/open_meeting/\"\n",
    "\n",
    "CSV_FILE = \"puct_meeting_links.csv\"\n",
    "\n",
    "def fetch_meeting_page(url):\n",
    "    \"\"\"Fetch the HTML content from the given URL.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def parse_meeting_links(html):\n",
    "    \"\"\"Parse HTML to extract meeting links from the past three years.\"\"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    meeting_links = []\n",
    "    \n",
    "    # cutoff date\n",
    "    today = datetime.today()\n",
    "    cutoff_date = datetime(2021, 1, 1)\n",
    "    \n",
    "    # loop through all <a> tags with an href attribute\n",
    "    for a_tag in soup.find_all(\"a\", href=True):\n",
    "        href = a_tag[\"href\"]\n",
    "        # check if the href matches the meeting URL pattern\n",
    "        if \"/tx/puct/open_meeting/\" in href:\n",
    "            parts = href.strip(\"/\").split(\"/\")\n",
    "            if len(parts) == 4:  # expecting something like: tx/puct/open_meeting/YYYYMMDD\n",
    "                date_str = parts[-1]\n",
    "                try:\n",
    "                    meeting_date = datetime.strptime(date_str, \"%Y%m%d\")\n",
    "                    if meeting_date >= cutoff_date:\n",
    "                        full_url = f\"https://www.adminmonitor.com{href}\"\n",
    "                        meeting_links.append((meeting_date.strftime(\"%Y-%m-%d\"), full_url))\n",
    "                except ValueError:\n",
    "                    # if the date string isn't in the expected format, skip it\n",
    "                    continue\n",
    "\n",
    "    # sort the meeting links in descending order by date\n",
    "    return sorted(meeting_links, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "def save_links_to_csv(links, filename):\n",
    "    \"\"\"Save the list of meeting links to a CSV file.\"\"\"\n",
    "    with open(filename, mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Date\", \"URL\"])\n",
    "        for date, url in links:\n",
    "            writer.writerow([date, url])\n",
    "    print(f\"Saved {len(links)} meeting links to {filename}\")\n",
    "\n",
    "def main():\n",
    "    html = fetch_meeting_page(BASE_URL)\n",
    "    if not html:\n",
    "        print(\"Failed to retrieve the meeting page.\")\n",
    "        return\n",
    "\n",
    "    meeting_links = parse_meeting_links(html)\n",
    "    if meeting_links:\n",
    "        save_links_to_csv(meeting_links, CSV_FILE)\n",
    "    else:\n",
    "        print(\"No meeting links found.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered meetings written to puct_meeting_links_filtered.csv\n"
     ]
    }
   ],
   "source": [
    "INPUT_CSV = 'puct_meeting_links.csv'\n",
    "OUTPUT_CSV = 'puct_meeting_links_filtered.csv'\n",
    "\n",
    "def filter_meetings(input_csv, output_csv):\n",
    "    unique_meetings = {}\n",
    "    today = datetime.today()\n",
    "\n",
    "    # read from the input CSV\n",
    "    with open(input_csv, newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            date_str = row['Date']  # expecting format YYYY-MM-DD\n",
    "            url = row['URL']\n",
    "            try:\n",
    "                meeting_date = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "            except ValueError:\n",
    "                # skip rows with invalid date format\n",
    "                continue\n",
    "\n",
    "            key = (date_str, url)\n",
    "            if key not in unique_meetings:\n",
    "                unique_meetings[key] = row\n",
    "\n",
    "    # sort by date descending (latest first)\n",
    "    sorted_meetings = sorted(unique_meetings.values(), key=lambda x: x['Date'], reverse=True)\n",
    "\n",
    "    # write the filtered, unique meetings to a new CSV file\n",
    "    with open(output_csv, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['Date', 'URL']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for row in sorted_meetings:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    print(f\"Filtered meetings written to {output_csv}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    filter_meetings(INPUT_CSV, OUTPUT_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 102 meeting rows to process.\n",
      "[1/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20250313/ ... Found master.m3u8.\n",
      "[2/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20250220/ ... Found master.m3u8.\n",
      "[3/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20250213/ ... Found master.m3u8.\n",
      "[4/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20250131/ ... Found master.m3u8.\n",
      "[5/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20250116/ ... Found master.m3u8.\n",
      "[6/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20241219/ ... Found master.m3u8.\n",
      "[7/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20241212/ ... Found master.m3u8.\n",
      "[8/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20241121/ ... Found master.m3u8.\n",
      "[9/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20241114/ ... Found master.m3u8.\n",
      "[10/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20241003/ ... Found master.m3u8.\n",
      "[11/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20240926/ ... Found master.m3u8.\n",
      "[12/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20240912/ ... Found master.m3u8.\n",
      "[13/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20240829/ ... Found master.m3u8.\n",
      "[14/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20240815/ ... Found master.m3u8.\n",
      "[15/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20240725/ ... Found master.m3u8.\n",
      "[16/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20240711/ ... Found master.m3u8.\n",
      "[17/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20240613/ ... Found master.m3u8.\n",
      "[18/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20240523/ ... Found master.m3u8.\n",
      "[19/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20240516/ ... Found master.m3u8.\n",
      "[20/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20240502/ ... Found master.m3u8.\n",
      "[21/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20240425/ ... Found master.m3u8.\n",
      "[22/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20240411/ ... Found master.m3u8.\n",
      "[23/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20240321/ ... Found master.m3u8.\n",
      "[24/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20240307/ ... Found master.m3u8.\n",
      "[25/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20240215/ ... Found master.m3u8.\n",
      "[26/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20240201/ ... Found master.m3u8.\n",
      "[27/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20240118/ ... Found master.m3u8.\n",
      "[28/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20231214/ ... Found master.m3u8.\n",
      "[29/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20231130/ ... Found master.m3u8.\n",
      "[30/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20231102/ ... Found master.m3u8.\n",
      "[31/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20231020/ ... Found master.m3u8.\n",
      "[32/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20231012/ ... Found master.m3u8.\n",
      "[33/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20230928/ ... Found master.m3u8.\n",
      "[34/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20230914/ ... Found master.m3u8.\n",
      "[35/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20230824/ ... Found master.m3u8.\n",
      "[36/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20230803/ ... Found master.m3u8.\n",
      "[37/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20230720/ ... Found master.m3u8.\n",
      "[38/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20230629/ ... Found master.m3u8.\n",
      "[39/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20230615/ ... Found master.m3u8.\n",
      "[40/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20230525/ ... Found master.m3u8.\n",
      "[41/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20230427/ ... Found master.m3u8.\n",
      "[42/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20230406/ ... Found master.m3u8.\n",
      "[43/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20230323/ ... Found master.m3u8.\n",
      "[44/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20230309/ ... Found master.m3u8.\n",
      "[45/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20230216/ ... Found master.m3u8.\n",
      "[46/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20230126/ ... Found master.m3u8.\n",
      "[47/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20230112/ ... Found master.m3u8.\n",
      "[48/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20221215/ ... Found master.m3u8.\n",
      "[49/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20221130/ ... Found master.m3u8.\n",
      "[50/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20221103/ ... Found master.m3u8.\n",
      "[51/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20221020/ ... Found master.m3u8.\n",
      "[52/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20221006/ ... Found master.m3u8.\n",
      "[53/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20220929/ ... Found master.m3u8.\n",
      "[54/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20220915/ ... Found master.m3u8.\n",
      "[55/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20220825/ ... Found master.m3u8.\n",
      "[56/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20220804/ ... Found master.m3u8.\n",
      "[57/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20220714/ ... Found master.m3u8.\n",
      "[58/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20220630/ ... Found master.m3u8.\n",
      "[59/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20220616/ ... Found master.m3u8.\n",
      "[60/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20220526/ ... Found master.m3u8.\n",
      "[61/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20220512/ ... Found master.m3u8.\n",
      "[62/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20220421/ ... Found master.m3u8.\n",
      "[63/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20220331/ ... Found master.m3u8.\n",
      "[64/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20220310/ ... Found master.m3u8.\n",
      "[65/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20220225/ ... Found master.m3u8.\n",
      "[66/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20220210/ ... Found master.m3u8.\n",
      "[67/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20220127/ ... Found master.m3u8.\n",
      "[68/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20220113/ ... Found master.m3u8.\n",
      "[69/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20211216/ ... Found master.m3u8.\n",
      "[70/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20211203/ ... Found master.m3u8.\n",
      "[71/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20211202/ ... Found master.m3u8.\n",
      "[72/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20211118/ ... Found master.m3u8.\n",
      "[73/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20211028/ ... Found master.m3u8.\n",
      "[74/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20211021/ ... Found master.m3u8.\n",
      "[75/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20211007/ ... Found master.m3u8.\n",
      "[76/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20210930/ ... Found master.m3u8.\n",
      "[77/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20210923/ ... Found master.m3u8.\n",
      "[78/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20210902/ ... Found master.m3u8.\n",
      "[79/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20210819/ ... Found master.m3u8.\n",
      "[80/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20210729/ ... Found master.m3u8.\n",
      "[81/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20210715/ ... Found master.m3u8.\n",
      "[82/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20210624/ ... Found master.m3u8.\n",
      "[83/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20210617/ ... Found master.m3u8.\n",
      "[84/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20210611/ ... Found master.m3u8.\n",
      "[85/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20210603/ ... Found master.m3u8.\n",
      "[86/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20210521/ ... Found master.m3u8.\n",
      "[87/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20210506/ ... Found master.m3u8.\n",
      "[88/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20210407/ ... Found master.m3u8.\n",
      "[89/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20210318/ ... No master.m3u8 found.\n",
      "[90/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20210312/ ... Found master.m3u8.\n",
      "[91/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20210311/ ... No master.m3u8 found.\n",
      "[92/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20210305/ ... Found master.m3u8.\n",
      "[93/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20210303/ ... Found master.m3u8.\n",
      "[94/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20210226/ ... No master.m3u8 found.\n",
      "[95/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20210221/ ... Found master.m3u8.\n",
      "[96/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20210219/ ... Found master.m3u8.\n",
      "[97/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20210217/ ... Found master.m3u8.\n",
      "[98/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20210216/ ... Found master.m3u8.\n",
      "[99/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20210215/ ... Found master.m3u8.\n",
      "[100/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20210212/ ... Found master.m3u8.\n",
      "[101/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20210129/ ... Found master.m3u8.\n",
      "[102/102] Processing: https://www.adminmonitor.com/tx/puct/open_meeting/20210114/ ... Found master.m3u8.\n",
      "Finished processing. Results saved to puct_meeting_links_with_m3u8.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import re\n",
    "import time\n",
    "\n",
    "INPUT_CSV = 'puct_meeting_links_filtered.csv'\n",
    "OUTPUT_CSV = 'puct_meeting_links_with_m3u8.csv'\n",
    "\n",
    "def extract_m3u8(url):\n",
    "    \"\"\"\n",
    "    Fetch the page at the given URL and extract the first occurrence\n",
    "    of a URL containing 'master.m3u8'. Returns an empty string if not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        html = response.text\n",
    "\n",
    "        m3u8_links = re.findall(r'(https?://[^\\'\" >]+master\\.m3u8)', html)\n",
    "        if m3u8_links:\n",
    "            return m3u8_links[0]\n",
    "        else:\n",
    "            return \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def main():\n",
    "    with open(INPUT_CSV, newline='', encoding='utf-8') as infile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        rows = list(reader)\n",
    "    \n",
    "    total = len(rows)\n",
    "    print(f\"Found {total} meeting rows to process.\")\n",
    "\n",
    "    with open(OUTPUT_CSV, 'w', newline='', encoding='utf-8') as outfile:\n",
    "        fieldnames = reader.fieldnames + ['m3u8_url']\n",
    "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for index, row in enumerate(rows, start=1):\n",
    "            meeting_url = row['URL']\n",
    "            print(f\"[{index}/{total}] Processing: {meeting_url}\", end=\" ... \")\n",
    "\n",
    "            m3u8_url = extract_m3u8(meeting_url)\n",
    "            if m3u8_url:\n",
    "                print(\"Found master.m3u8.\")\n",
    "            else:\n",
    "                print(\"No master.m3u8 found.\")\n",
    "\n",
    "            row['m3u8_url'] = m3u8_url \n",
    "            writer.writerow(row)\n",
    "            # be polite to the server with a short delay\n",
    "            time.sleep(1)\n",
    "\n",
    "    print(f\"Finished processing. Results saved to {OUTPUT_CSV}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OpenAI API key has been set.\n",
      "\n",
      "----- All meetings processed -----\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import subprocess\n",
    "from pydub import AudioSegment\n",
    "import openai\n",
    "\n",
    "\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai.api_key:\n",
    "    raise ValueError(\"OpenAI API key not set. Please set the OPENAI_API_KEY environment variable.\")\n",
    "else:   \n",
    "    print(\"OpenAI API key has been set.\\n\")\n",
    "\n",
    "\n",
    "csv_file = \"puct_meeting_links_with_m3u8.csv\"  # csv with columns date, url, m3u8_url\n",
    "mp3_dir = \"mp3_files\"\n",
    "transcripts_dir = \"transcripts\"\n",
    "\n",
    "\n",
    "os.makedirs(mp3_dir, exist_ok=True)\n",
    "os.makedirs(transcripts_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "CHUNK_SIZE_MB = 25\n",
    "\n",
    "\n",
    "def convert_m3u8_to_mp3(m3u8_url, output_mp3_path):\n",
    "    \"\"\"\n",
    "    Uses ffmpeg to download the audio from the m3u8 stream and converts it to an MP3 file.\n",
    "    \"\"\"\n",
    "    print(f\"Extracting audio from m3u8 URL:\\n{m3u8_url}\")\n",
    "    ffmpeg_cmd = [\n",
    "        \"ffmpeg\", \"-y\",               # Overwrite without prompting\n",
    "        \"-i\", m3u8_url,               # Input m3u8 URL\n",
    "        \"-vn\",                        # No video\n",
    "        \"-ar\", \"16000\",               # Set audio sample rate to 16kHz\n",
    "        \"-ac\", \"1\",                   # Mono audio\n",
    "        output_mp3_path\n",
    "    ]\n",
    "    print(\"Running ffmpeg command:\")\n",
    "    print(\" \".join(ffmpeg_cmd))\n",
    "    subprocess.run(ffmpeg_cmd, check=True)\n",
    "    print(f\"Audio extracted and saved as {output_mp3_path}\\n\")\n",
    "\n",
    "\n",
    "def split_audio(file_path):\n",
    "    \"\"\"\n",
    "    Splits an MP3 file into in-memory chunks, ensuring each chunk is under 25MB.\n",
    "    Returns a list of AudioSegment chunks.\n",
    "    \"\"\"\n",
    "    max_size_bytes = CHUNK_SIZE_MB * 1024 * 1024\n",
    "    audio = AudioSegment.from_mp3(file_path)\n",
    "    chunks = []\n",
    "    queue = [audio]\n",
    "\n",
    "    while queue:\n",
    "        chunk = queue.pop(0)\n",
    "        # save temporarily in memory and check size\n",
    "        temp_path = \"temp_check.mp3\"\n",
    "        chunk.export(temp_path, format=\"mp3\")\n",
    "        chunk_size = os.path.getsize(temp_path)\n",
    "        os.remove(temp_path)\n",
    "\n",
    "        if chunk_size > max_size_bytes:\n",
    "            # split into two halves and recheck\n",
    "            midpoint = len(chunk) // 2\n",
    "            queue.append(chunk[:midpoint])\n",
    "            queue.append(chunk[midpoint:])\n",
    "        else:\n",
    "            chunks.append(chunk)\n",
    "\n",
    "    print(f\"Total chunks created: {len(chunks)}\\n\")\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def transcribe_audio(audio_chunk, chunk_index):\n",
    "    \"\"\"\n",
    "    Transcribes an in-memory MP3 chunk using OpenAI Whisper API.\n",
    "    Saves the chunk temporarily as 'temp_chunk.mp3' and returns the list of segments.\n",
    "    \"\"\"\n",
    "    temp_file = \"temp_chunk.mp3\"\n",
    "    audio_chunk.export(temp_file, format=\"mp3\")\n",
    "    print(f\"Transcribing chunk {chunk_index} (temporary file: {temp_file})...\")\n",
    "    with open(temp_file, \"rb\") as audio_file:\n",
    "        response = openai.audio.transcriptions.create(\n",
    "            model=\"whisper-1\",\n",
    "            file=audio_file,\n",
    "            response_format=\"verbose_json\",\n",
    "            timestamp_granularities=[\"segment\"]\n",
    "        )\n",
    "    os.remove(temp_file)\n",
    "    print(f\"Finished transcribing chunk {chunk_index}\\n\")\n",
    "\n",
    "    return response.model_dump()[\"segments\"]\n",
    "\n",
    "\n",
    "def process_meeting(mp3_path, transcript_json_path):\n",
    "    \"\"\"\n",
    "    Processes an MP3 file:\n",
    "      - If its size exceeds 25MB, split it into chunks.\n",
    "      - Transcribe each chunk.\n",
    "      - Merge the transcriptions (adjusting timestamps by chunk offset).\n",
    "      - Save the final transcript as JSON.\n",
    "    \"\"\"\n",
    "    print(f\"Processing MP3 file: {mp3_path}\")\n",
    "    if os.path.getsize(mp3_path) > 25_000_000:\n",
    "        print(\"File exceeds 25MB; splitting into chunks...\")\n",
    "        chunks = split_audio(mp3_path)\n",
    "    else:\n",
    "        print(\"File is within size limits; processing as a single chunk.\\n\")\n",
    "        chunks = [AudioSegment.from_mp3(mp3_path)]\n",
    "    \n",
    "    full_transcript = []\n",
    "    cumulative_offset = 0.0  # in seconds\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        print(f\"Transcribing chunk {idx+1}/{len(chunks)}...\")\n",
    "        try:\n",
    "            segments = transcribe_audio(chunk, idx)\n",
    "        except Exception as e:\n",
    "            print(f\"Error transcribing chunk {idx}: {e}\")\n",
    "            continue\n",
    "        # duration of this chunk in seconds\n",
    "        chunk_duration_sec = len(chunk) / 1000.0\n",
    "        print(f\"Chunk {idx+1} duration: {chunk_duration_sec:.2f} seconds. Applying offset: {cumulative_offset:.2f} seconds.\")\n",
    "        for seg in segments:\n",
    "            seg_start = float(seg.get(\"start\", 0)) + cumulative_offset\n",
    "            seg_end = float(seg.get(\"end\", 0)) + cumulative_offset\n",
    "            full_transcript.append({\n",
    "                \"text\": seg.get(\"text\", \"\").strip(),\n",
    "                \"start\": round(seg_start, 4),\n",
    "                \"duration\": round(seg_end - seg_start, 4)\n",
    "            })\n",
    "        cumulative_offset += chunk_duration_sec\n",
    "\n",
    "    try:\n",
    "        with open(transcript_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(full_transcript, f, indent=4)\n",
    "        print(f\"Transcript saved to {transcript_json_path}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to write transcript JSON for {mp3_path}: {e}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    with open(csv_file, newline=\"\", encoding=\"utf-8\") as f:\n",
    "        meetings = list(csv.DictReader(f))\n",
    "\n",
    "    print(f\"Found {len(meetings)} meetings\\n\")\n",
    "    for idx, row in enumerate(meetings, start=1):\n",
    "        meeting_date = row.get(\"Date\", \"unknown\").replace(\"/\", \"-\")\n",
    "        m3u8_url     = row.get(\"m3u8_url\", \"\").strip()\n",
    "        if not m3u8_url:\n",
    "            print(f\"[{idx}] No URL for {meeting_date}, skipping.\\n\")\n",
    "            continue\n",
    "\n",
    "        mp3_filename          = f\"{meeting_date}.mp3\"\n",
    "        mp3_path              = os.path.join(mp3_dir, mp3_filename)\n",
    "        transcript_json_name  = f\"{meeting_date}_transcript.json\"\n",
    "        transcript_json_path  = os.path.join(transcripts_dir, transcript_json_name)\n",
    "\n",
    "\n",
    "        if os.path.exists(transcript_json_path):\n",
    "            print(f\"[{idx}] Transcript already exists for {meeting_date}, skipping transcription.\\n\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        if os.path.exists(mp3_path):\n",
    "            print(f\"[{idx}] MP3 already exists for {meeting_date}, skipping conversion.\\n\")\n",
    "        else:\n",
    "            print(f\"[{idx}] Converting m3u8 stream for {meeting_date} to MP3...\")\n",
    "            try:\n",
    "                convert_m3u8_to_mp3(m3u8_url, mp3_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error converting m3u8 for {meeting_date}: {e}\\n\")\n",
    "                continue\n",
    "\n",
    "\n",
    "        try:\n",
    "            process_meeting(mp3_path, transcript_json_path)\n",
    "            print(f\"[{idx}] Completed {meeting_date}\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing meeting on {meeting_date}: {e}\\n\")\n",
    "            continue\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # main()\n",
    "    print(\"----- All meetings processed -----\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
