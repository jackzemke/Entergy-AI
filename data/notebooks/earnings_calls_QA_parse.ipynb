{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "from PyPDF2 import PdfReader\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pages_from_pdf(pdf_path):\n",
    "    pages = list(extract_pages(pdf_path))\n",
    "    return pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_qa_order_from_header(page):\n",
    "    qa_order = []\n",
    "    header_text = \"\"\n",
    "    # Assume that the header is within the first few text boxes\n",
    "    for element in page:\n",
    "        if isinstance(element, LTTextContainer):\n",
    "            text = element.get_text()\n",
    "            # Check if the text contains 'Q -' or 'A -'\n",
    "            if 'Q -' in text or 'A -' in text:\n",
    "                header_text += text\n",
    "            # Break if we've gone past the header\n",
    "            if len(header_text) > 0 and ('{BIO' in text or not ('Q -' in text or 'A -' in text)):\n",
    "                break\n",
    "    # Extract the sequence of Q and A with speaker names\n",
    "    lines = header_text.strip().split('\\n')\n",
    "    for line in lines:\n",
    "        match = re.match(r'(Q|A)\\s*-\\s*(.+)', line)\n",
    "        if match:\n",
    "            qa_order.append({'label': match.group(1), 'speaker': match.group(2).strip()})\n",
    "        elif 'Operator' in line:\n",
    "            qa_order.append({'label': 'Operator', 'speaker': 'Operator'})\n",
    "    return qa_order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_speech_segments(page):\n",
    "    page_text = ''\n",
    "    for element in page:\n",
    "        if isinstance(element, LTTextContainer):\n",
    "            page_text += element.get_text()\n",
    "    # Split the text into segments based on {BIO ... <GO>} markers\n",
    "    segments = re.split(r'(\\{BIO \\d+ <GO>\\})', page_text)\n",
    "    # Remove empty strings and strip whitespace\n",
    "    segments = [seg.strip() for seg in segments if seg.strip()]\n",
    "    return segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_speeches_to_qa_labels(segments, qa_order):\n",
    "    qa_pairs = []\n",
    "    qa_index = 0  # Index in the qa_order list\n",
    "    current_speech = ''\n",
    "    current_speaker = ''\n",
    "    mapped_segments = []\n",
    "\n",
    "    for segment in segments:\n",
    "        # Check if the segment is a speaker marker\n",
    "        speaker_match = re.match(r'\\{BIO (\\d+) <GO>\\}', segment)\n",
    "        if speaker_match:\n",
    "            # Save the previous speech if any\n",
    "            if current_speech and current_speaker:\n",
    "                mapped_segments.append({'speaker': current_speaker, 'speech': current_speech})\n",
    "                current_speech = ''\n",
    "            # Reset current_speaker\n",
    "            current_speaker = ''\n",
    "        else:\n",
    "            # Assume the next non-marker segment is the speaker's name or speech\n",
    "            if not current_speaker:\n",
    "                # First line might be the speaker's name\n",
    "                lines = segment.split('\\n')\n",
    "                if len(lines) > 0:\n",
    "                    current_speaker = lines[0].strip()\n",
    "                    current_speech = '\\n'.join(lines[1:]).strip()\n",
    "                else:\n",
    "                    current_speech = segment\n",
    "            else:\n",
    "                current_speech += ' ' + segment\n",
    "\n",
    "    # Add the last speech\n",
    "    if current_speech and current_speaker:\n",
    "        mapped_segments.append({'speaker': current_speaker, 'speech': current_speech})\n",
    "\n",
    "    # Now map the speeches to Q&A labels based on the qa_order\n",
    "    for seg in mapped_segments:\n",
    "        if qa_index < len(qa_order):\n",
    "            qa = qa_order[qa_index]\n",
    "            # Check if the speaker matches\n",
    "            if qa['speaker'].startswith(seg['speaker']):\n",
    "                qa_pairs.append({'label': qa['label'], 'speaker': seg['speaker'], 'speech': seg['speech']})\n",
    "                qa_index += 1\n",
    "            else:\n",
    "                # Handle cases where the speaker name doesn't match exactly\n",
    "                qa_pairs.append({'label': 'Unknown', 'speaker': seg['speaker'], 'speech': seg['speech']})\n",
    "        else:\n",
    "            qa_pairs.append({'label': 'Unknown', 'speaker': seg['speaker'], 'speech': seg['speech']})\n",
    "\n",
    "    return qa_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_qa_pairs(qa_pairs_page):\n",
    "    questions = []\n",
    "    answers = []\n",
    "    collected_pairs = []\n",
    "    last_question = ''\n",
    "    last_question_speaker = ''\n",
    "    for qa in qa_pairs_page:\n",
    "        if qa['label'] == 'Q':\n",
    "            if last_question and answers:\n",
    "                # Pair the last question with the collected answers\n",
    "                collected_pairs.append({'question': last_question, 'question_speaker': last_question_speaker, 'answer': ' '.join(answers)})\n",
    "                answers = []\n",
    "            last_question = qa['speech']\n",
    "            last_question_speaker = qa['speaker']\n",
    "        elif qa['label'] == 'A':\n",
    "            answers.append(qa['speech'])\n",
    "    # Handle the last Q&A pair\n",
    "    if last_question and answers:\n",
    "        collected_pairs.append({'question': last_question, 'question_speaker': last_question_speaker, 'answer': ' '.join(answers)})\n",
    "    return collected_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf(pdf_path):\n",
    "    pages = extract_pages_from_pdf(pdf_path)\n",
    "    all_qa_pairs = []\n",
    "    for page in pages:\n",
    "        # Extract the Q&A order from the page header\n",
    "        qa_order = extract_qa_order_from_header(page)\n",
    "        if not qa_order:\n",
    "            continue  # Skip pages without Q&A order\n",
    "        # Split speech segments\n",
    "        segments = split_speech_segments(page)\n",
    "        # Map speeches to Q&A labels\n",
    "        qa_pairs_page = map_speeches_to_qa_labels(segments, qa_order)\n",
    "        # Collect Q&A pairs from the page\n",
    "        collected_pairs = collect_qa_pairs(qa_pairs_page)\n",
    "        all_qa_pairs.extend(collected_pairs)\n",
    "    return all_qa_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_qa_pairs_to_csv(qa_pairs, csv_file_path):\n",
    "    with open(csv_file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['Question Speaker', 'Question', 'Answer']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for pair in qa_pairs:\n",
    "            writer.writerow({\n",
    "                'Question Speaker': pair['question_speaker'],\n",
    "                'Question': pair['question'],\n",
    "                'Answer': pair['answer']\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = '/Users/petersapountzis/Desktop/tulane/fall2024/cmps4010/BB_Docs_20240909_172015/20121105_Entergy_Corp-_Earnings_Call_2012-11-05_SD000000002694979962.pdf'\n",
    "csv_file_path = 'earnings_questions_2012_11_05.csv'\n",
    "\n",
    "# Process the PDF and collect Q&A pairs\n",
    "qa_pairs = process_pdf(pdf_path)\n",
    "\n",
    "# Save the Q&A pairs to CSV\n",
    "save_qa_pairs_to_csv(qa_pairs, csv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (vibes env)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
